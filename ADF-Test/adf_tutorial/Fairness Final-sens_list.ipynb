{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0725 16:32:28.079162 140638759790400 saver.py:1399] Restoring parameters from ../models/census/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3/dist-packages/tensorflow/python/util/dispatch.py:1096: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0725 16:32:28.123535 140638759790400 deprecation.py:341] From /usr/lib/python3/dist-packages/tensorflow/python/util/dispatch.py:1096: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-53586853609e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    509\u001b[0m     \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epsillon'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.025\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'the value of epsillon for partitioning'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m     \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_float\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'max_k_iter'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'the percentage of max_iter if K is not increased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mmain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_parse_flags_tolerate_undef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3/dist-packages/absl/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv, flags_parser)\u001b[0m\n\u001b[1;32m    301\u001b[0m       \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m       \u001b[0m_run_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mUsageError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m       \u001b[0musage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshorthelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetailed_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/absl/app.py\u001b[0m in \u001b[0;36m_run_main\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-53586853609e>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m     dnn_fair_testing(dataset = FLAGS.dataset, \n\u001b[0m\u001b[1;32m    492\u001b[0m                      \u001b[0msens_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msens_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m                      \u001b[0mmodel_path\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-53586853609e>\u001b[0m in \u001b[0;36mdnn_fair_testing\u001b[0;34m(dataset, sens_params, model_path, cluster_num, max_global, max_local, max_iter, epsillon, max_k_iter)\u001b[0m\n\u001b[1;32m    295\u001b[0m     \u001b[0msample_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0msample_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'labels'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m     \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;31m#-----------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "from itertools import product\n",
    "import itertools\n",
    "import tensorflow.compat.v1 as tf \n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import sys, os\n",
    "sys.path.append(\"../\")\n",
    "import copy\n",
    "import pandas as pd\n",
    "from tensorflow.python.platform import flags\n",
    "from scipy.optimize import basinhopping\n",
    "import time\n",
    "from adf_data.census import census_data\n",
    "from adf_data.credit import credit_data\n",
    "from adf_data.compas import compas_data\n",
    "from adf_data.default import default_data\n",
    "from adf_data.bank import bank_data\n",
    "from adf_data.heart import heart_data\n",
    "from adf_model.tutorial_models import dnn\n",
    "from adf_utils.utils_tf import model_prediction, model_argmax , layer_out\n",
    "from adf_utils.config import census, credit, bank, compas, default, heart\n",
    "from adf_tutorial.utils import cluster, gradient_graph\n",
    "#from IPython.display import clear_output\n",
    "\n",
    "\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "\n",
    "# step size of perturbation\n",
    "perturbation_size = 1\n",
    "\n",
    "def check_for_error_condition(conf, sess, x, preds, t, sens_params, input_shape, epsillon):\n",
    "    \"\"\"\n",
    "    Check whether the test case is an individual discriminatory instance\n",
    "    :param conf: the configuration of dataset\n",
    "    :param sess: TF session\n",
    "    :param x: input placeholder\n",
    "    :param preds: the model's symbolic output\n",
    "    :param t: test case\n",
    "    :param sens: the index of sensitive feature\n",
    "    :return: whether it is an individual discriminatory instance\n",
    "    \"\"\"\n",
    "    global time_first_disc\n",
    "    global start_time\n",
    "    t = [t.astype('int')]    \n",
    "    samples = m_instance( np.array(t), sens_params, conf )   \n",
    "    pred = pred_prob(sess, x, preds, samples , input_shape )\n",
    "    partition = clustering(pred,samples, sens_params , epsillon)\n",
    "    if time_first_disc == 0:\n",
    "        if (0 in model_argmax(sess, x, preds, samples.reshape(len(samples),input_shape[1]))) and \\\n",
    "           (1 in model_argmax(sess, x, preds, samples.reshape(len(samples),input_shape[1]))):\n",
    "            time_first_disc =round( (time.time() - start_time) ,4)\n",
    "\n",
    "    return  max(list(partition.keys())[1:]) - min(list(partition.keys())[1:]) , len(partition)-1#(len(partition) -1),\n",
    "    \n",
    "def seed_test_input(clusters, limit):\n",
    "    \"\"\"\n",
    "    Select the seed inputs for fairness testing\n",
    "    :param clusters: the results of K-means clustering\n",
    "    :param limit: the size of seed inputs wanted\n",
    "    :return: a sequence of seed inputs\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    rows = []\n",
    "    max_size = max([len(c[0]) for c in clusters])\n",
    "    while i < max_size:\n",
    "        if len(rows) == limit:\n",
    "            break\n",
    "        for c in clusters:\n",
    "            if i >= len(c[0]):\n",
    "                continue\n",
    "            row = c[0][i]\n",
    "            rows.append(row)\n",
    "            if len(rows) == limit:\n",
    "                break\n",
    "        i += 1\n",
    "    return np.array(rows)\n",
    "\n",
    "def clip(input, conf):\n",
    "    \"\"\"\n",
    "    Clip the generating instance with each feature to make sure it is valid\n",
    "    :param input: generating instance\n",
    "    :param conf: the configuration of dataset\n",
    "    :return: a valid generating instance\n",
    "    \"\"\"\n",
    "    for i in range(len(input)):\n",
    "        input[i] = max(input[i], conf.input_bounds[i][0])\n",
    "        input[i] = min(input[i], conf.input_bounds[i][1])\n",
    "    return input\n",
    "\n",
    "class Local_Perturbation(object):\n",
    "    \"\"\"\n",
    "    The  implementation of local perturbation\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sess, grad, x, n_values, sens_params, input_shape, conf):\n",
    "        \"\"\"\n",
    "        Initial function of local perturbation\n",
    "        :param sess: TF session\n",
    "        :param grad: the gradient graph\n",
    "        :param x: input placeholder\n",
    "        :param n_value: the discriminatory value of sensitive feature\n",
    "        :param sens_param: the index of sensitive feature\n",
    "        :param input_shape: the shape of dataset\n",
    "        :param conf: the configuration of dataset\n",
    "        \"\"\"\n",
    "        self.sess = sess\n",
    "        self.grad = grad\n",
    "        self.x = x\n",
    "        self.n_values = n_values\n",
    "        self.input_shape = input_shape\n",
    "        self.sens = sens_params\n",
    "        self.conf = conf\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \"\"\"\n",
    "        Local perturbation\n",
    "        :param x: input instance for local perturbation\n",
    "        :return: new potential individual discriminatory instance\n",
    "        \"\"\"\n",
    "\n",
    "        # perturbation\n",
    "        s = np.random.choice([1.0, -1.0]) * perturbation_size\n",
    "\n",
    "        n_x = x.copy()\n",
    "        for i in range(len(self.sens)):\n",
    "            n_x[self.sens[i] - 1] = self.n_values[i]\n",
    "            \n",
    "        # compute the gradients of an individual discriminatory instance pairs\n",
    "        ind_grad = self.sess.run(self.grad, feed_dict={self.x:np.array([x])})\n",
    "        n_ind_grad = self.sess.run(self.grad, feed_dict={self.x:np.array([n_x])})\n",
    "\n",
    "        if np.zeros(self.input_shape).tolist() == ind_grad[0].tolist() and \\\n",
    "           np.zeros(self.input_shape).tolist() == n_ind_grad[0].tolist():\n",
    "            probs = 1.0 / (self.input_shape) * np.ones(self.input_shape)\n",
    "\n",
    "            for sens in self.sens :\n",
    "                probs[sens - 1] = 0\n",
    "\n",
    "                \n",
    "\n",
    "        else:\n",
    "            # nomalize the reciprocal of gradients (prefer the low impactful feature)\n",
    "            grad_sum = 1.0 / (abs(ind_grad[0]) + abs(n_ind_grad[0]))\n",
    "\n",
    "            for sens in self.sens :\n",
    "                grad_sum[ sens - 1 ] = 0\n",
    "\n",
    "            probs = grad_sum / np.sum(grad_sum)\n",
    "        probs = probs/probs.sum()\n",
    "        if True in np.isnan(probs):\n",
    "            probs = 1.0 / (self.input_shape) * np.ones(self.input_shape)\n",
    "\n",
    "            for sens in self.sens :\n",
    "                probs[sens - 1] = 0\n",
    "            probs = probs/probs.sum()\n",
    "\n",
    "\n",
    "        # randomly choose the feature for local perturbation\n",
    "        index = np.random.choice(range(self.input_shape) , p=probs)\n",
    "        local_cal_grad = np.zeros(self.input_shape)\n",
    "        local_cal_grad[index] = 1.0\n",
    "        x = clip(x + s * local_cal_grad, self.conf).astype(\"int\")\n",
    "        return x\n",
    "                \n",
    "#--------------------------------------\n",
    "def m_instance( sample, sens_params, conf):\n",
    "    index = []\n",
    "    m_sample = []\n",
    "    for sens in sens_params:\n",
    "        index.append([i for i in range(conf.input_bounds[sens-1][0], conf.input_bounds[sens-1][1]+1)])\n",
    "      \n",
    "    for ind in list(product(*index)):     \n",
    "        temp = sample.copy()\n",
    "        for i in range(len(sens_params)):\n",
    "            temp[0][sens_params[i]-1] = ind[i]\n",
    "        m_sample.append(temp)\n",
    "    return np.array(m_sample)\n",
    "\n",
    "def global_sample_select(clus_dic, sens_params):\n",
    "    leng = 0\n",
    "    for key in clus_dic.keys():\n",
    "        if key == 'Seed':\n",
    "            continue\n",
    "        if len(clus_dic[key]) > leng:\n",
    "            leng = len(clus_dic[key])\n",
    "            largest = key\n",
    "    \n",
    "    sample_ind = np.random.randint(len(clus_dic[largest]))\n",
    "    n_sample_ind = np.random.randint(len(clus_dic[largest]))\n",
    "    \n",
    "    sample = clus_dic['Seed']\n",
    "    for i in range(len(sens_params)):\n",
    "        sample[sens_params[i] -1] = clus_dic[largest][sample_ind][i]\n",
    "    # returns one sample of largest partition and its pair\n",
    "    return np.array([sample]),clus_dic[largest][n_sample_ind]\n",
    "\n",
    "\n",
    "def local_sample_select(clus_dic, sens_params):\n",
    "      \n",
    "    k_1 = min(list(clus_dic.keys())[1:])\n",
    "    k_2 = max(list(clus_dic.keys())[1:])\n",
    "    \n",
    "    sample_ind = np.random.randint(len(clus_dic[k_1]))\n",
    "    n_sample_ind = np.random.randint(len(clus_dic[k_2]))\n",
    "\n",
    "    sample = clus_dic['Seed']\n",
    "    for i in range(len(sens_params)):\n",
    "        sample[sens_params[i] -1] = clus_dic[k_1][sample_ind][i]\n",
    "    return np.array([sample]),clus_dic[k_2][n_sample_ind]\n",
    "    \n",
    "def clustering(probs,m_sample, sens_params, epsillon):\n",
    "    cluster_dic = {}\n",
    "    cluster_dic['Seed'] = m_sample[0][0]\n",
    "  \n",
    "    for i in range(len(probs)):     \n",
    "        #  to avoid k = Max + 1\n",
    "        if probs[i] == 1.0:\n",
    "            if (int( probs[i] / epsillon ) - 1) not in cluster_dic.keys():            \n",
    "                cluster_dic[ (int( probs[i] / epsillon ) -1)] = [ [m_sample[i][0][j - 1] for j in sens_params]]           \n",
    "            else:\n",
    "                cluster_dic[ (int( probs[i] / epsillon ) -1)].append( [m_sample[i][0][j - 1] for j in sens_params] )              \n",
    "        elif int( probs[i] / epsillon ) not in cluster_dic.keys():\n",
    "                cluster_dic[ int( probs[i] / epsillon )] = [ [m_sample[i][0][j - 1] for j in sens_params] ]           \n",
    "        else:\n",
    "                cluster_dic[ int( probs[i] / epsillon)].append( [m_sample[i][0][j - 1] for j in sens_params] )\n",
    "\n",
    "    return cluster_dic  \n",
    "\n",
    "    \n",
    "def pred_prob(sess, x, preds, m_sample, input_shape):\n",
    "        probs = model_prediction(sess, x, preds, np.array(m_sample).reshape(len(m_sample),\n",
    "                                                                input_shape[1]))[:,1:2].reshape(len(m_sample))\n",
    "        return probs\n",
    "#-------------------------------------------\n",
    "    \n",
    "def dnn_fair_testing(dataset, sens_params, model_path, cluster_num, \n",
    "                     max_global, max_local, max_iter, epsillon, max_k_iter):\n",
    "    \"\"\"\n",
    "    \n",
    "    The implementation of ADF\n",
    "    :param dataset: the name of testing dataset\n",
    "    :param sensitive_param: the index of sensitive feature\n",
    "    :param model_path: the path of testing model\n",
    "    :param cluster_num: the number of clusters to form as well as the number of\n",
    "            centroids to generate\n",
    "    :param max_global: the maximum number of samples for global search\n",
    "    :param max_local: the maximum number of samples for local search\n",
    "    :param max_iter: the maximum iteration of global perturbation\n",
    "    \"\"\"\n",
    "    data = {\"census\":census_data, \"credit\":credit_data, \"bank\":bank_data, \"compas\":compas_data, \n",
    "            \"default\": default_data, \"heart\":heart_data}\n",
    "    data_config = {\"census\":census, \"credit\":credit, \"bank\":bank, \"compas\":compas, \"default\":default,\n",
    "                  \"heart\":heart}\n",
    "    # prepare the testing data and model\n",
    "    X, Y, input_shape, nb_classes = data[dataset]()\n",
    "    tf.set_random_seed(1234)\n",
    "\n",
    "    config = tf.ConfigProto(device_count = {'GPU': 0})\n",
    "    config.allow_soft_placement= True\n",
    "\n",
    "    sess = tf.Session(config=config)\n",
    "    x = tf.placeholder(tf.float32, shape=input_shape)\n",
    "    y = tf.placeholder(tf.float32, shape=(None, nb_classes))\n",
    "    model = dnn(input_shape, nb_classes)   \n",
    "\n",
    "    preds = model(x)\n",
    "    saver = tf.train.Saver()\n",
    "    model_path = model_path + dataset + \"/test.model\"\n",
    "    saver.restore(sess, model_path)\n",
    "\n",
    "    # construct the gradient graph\n",
    "    grad_0 = gradient_graph(x, preds)\n",
    "\n",
    "    # build the clustering model\n",
    "    clf = cluster(dataset, cluster_num)\n",
    "    clusters = [np.where(clf.labels_ == i) for i in range(cluster_num)]\n",
    "\n",
    "    # store the result of fairness testing\n",
    "    global_disc_inputs = set()\n",
    "    global_disc_inputs_list = []\n",
    "    local_disc_inputs = set()\n",
    "    local_disc_inputs_list = []\n",
    "    total_dis = 0\n",
    "    global max_k\n",
    "    global start_time\n",
    "    global max_k_time\n",
    "    global time_first_disc\n",
    "    global sample_df\n",
    "    time_first_disc = 0\n",
    "    zz=np.load('../results/census/RQ1&2/local_samples_1.npy').astype('int32')[:,:-4]\n",
    "    samples = m_instance( np.array([zz[0]]), sens_params, data_config[dataset])\n",
    "    labels = model_argmax(sess, x, preds, np.array(samples).reshape(len(samples),input_shape[1]))\n",
    "    sample_df = pd.DataFrame(samples.reshape((90,13)))\n",
    "    sample_df['labels'] = labels\n",
    "    input(sample_df)\n",
    "    #-----------------------\n",
    "    def evaluate_local(inp):\n",
    "        \n",
    "        \"\"\"\n",
    "        Evaluate whether the test input after local perturbation is an individual discriminatory instance\n",
    "        :param inp: test input\n",
    "        :return: whether it is an individual discriminatory instance\n",
    "        \"\"\" \n",
    "        global max_k\n",
    "        global max_k_time\n",
    "        global start_time\n",
    "        result, K = check_for_error_condition(data_config[dataset], sess, x, preds, inp, \n",
    "                                           sens_params, input_shape, epsillon)    \n",
    "        if K > max_k:\n",
    "            max_k = K \n",
    "            max_k_time = time.time() - start_time\n",
    "        \n",
    "        dis_sample =copy.deepcopy(inp.astype('int').tolist())   \n",
    "        for sens in sens_params:\n",
    "            dis_sample[sens - 1] = 0\n",
    "            \n",
    "        if tuple(dis_sample) not in global_disc_inputs and\\\n",
    "                                tuple(dis_sample) not in local_disc_inputs:\n",
    "            local_disc_inputs.add(tuple(dis_sample))\n",
    "            local_disc_inputs_list.append(dis_sample + [init_k] + [max_k] + [round(max_k_time,4)] + [seed_num])\n",
    "\n",
    "        return (-1 * result)\n",
    "\n",
    "    # select the seed input for fairness testing\n",
    "    inputs = seed_test_input(clusters, min(max_global, len(X))) \n",
    "    seed_num = 0\n",
    "    time1 = time.time()    \n",
    "    max_k_time = 0\n",
    "    for num in range(len(inputs)):\n",
    "        #clear_output(wait=True)\n",
    "        start_time = time.time()\n",
    "        if time.time()-time1 >300:break \n",
    "        print('---------------')\n",
    "        print('Input ',seed_num)\n",
    "        index = inputs[num]\n",
    "        sample = X[ index : index + 1]\n",
    "        max_k_g = 0\n",
    "        clock = 0\n",
    "        # start global perturbation\n",
    "        for iter in range( max_iter + 1 ):            \n",
    "            if time.time()-time1 > 300 :\n",
    "                break\n",
    "                \n",
    "            m_sample = m_instance( sample , sens_params, data_config[dataset] )  \n",
    "            pred = pred_prob( sess, x, preds, m_sample , input_shape )\n",
    "            clus_dic = clustering( pred, m_sample, sens_params, epsillon )\n",
    "            \n",
    "            if iter == 0:\n",
    "                print()\n",
    "                init_k = len(clus_dic) - 1\n",
    "                max_k = init_k\n",
    "                max_k_time = round((time.time() - start_time),4)\n",
    "                print('init K => ',init_k)\n",
    "                \n",
    "            if len(clus_dic) - 1 > max_k:\n",
    "                max_k = len(clus_dic) - 1\n",
    "                max_k_time = round((time.time() - start_time),4)\n",
    "                \n",
    "            \n",
    "\n",
    "            sample,n_values = global_sample_select( clus_dic, sens_params )\n",
    "            \n",
    "\n",
    "                \n",
    "          \n",
    "            if len(clus_dic)-1 >= 2:\n",
    "                loc_x,n_values = local_sample_select(clus_dic ,sens_params )                              \n",
    "                minimizer = {\"method\": \"L-BFGS-B\"}\n",
    "                local_perturbation = Local_Perturbation(sess, grad_0, x, n_values, \n",
    "                                                        sens_params, input_shape[1], \n",
    "                                                        data_config[dataset])               \n",
    "                basinhopping(evaluate_local, loc_x, stepsize = 1.0, \n",
    "                             take_step = local_perturbation, minimizer_kwargs = minimizer, \n",
    "                             niter = max_local)\n",
    "                        \n",
    "                    \n",
    "            #print('global',max_k)\n",
    "            dis_sample = sample.copy()\n",
    "            for sens in sens_params:\n",
    "                dis_sample[0][sens  - 1] = 0\n",
    "            if tuple(dis_sample[0].astype('int')) not in global_disc_inputs and\\\n",
    "                                tuple(dis_sample[0].astype('int')) not in local_disc_inputs:\n",
    "            \n",
    "                global_disc_inputs.add(tuple(dis_sample[0].astype('int')))\n",
    "                global_disc_inputs_list.append(dis_sample[0].astype('int').tolist() +\\\n",
    "                                               [init_k] + [max_k] + [round(max_k_time,4)] + [seed_num])\n",
    "                \n",
    "            clus_dic = {}\n",
    "            if iter == max_iter:\n",
    "                break\n",
    "                \n",
    "#             if max_k_g < max_k:\n",
    "#                 max_k_g = max_k\n",
    "#                 clock = 0\n",
    "#             else:\n",
    "#                 clock += 1\n",
    "                \n",
    "\n",
    "#             if clock >= 50:\n",
    "#                 print('Failed to increase K in 30 consequtive runs')\n",
    "#                 break\n",
    "                \n",
    "            #Making up n_sample\n",
    "            n_sample = sample.copy()\n",
    "            for i in range(len(sens_params)):\n",
    "                n_sample[0][sens_params[i] - 1] = n_values[i]                \n",
    "            \n",
    "            # global perturbation\n",
    "            s_grad = sess.run(tf.sign(grad_0), feed_dict = {x: sample})\n",
    "            n_grad = sess.run(tf.sign(grad_0), feed_dict = {x: n_sample})\n",
    "            # find the feature with same impact\n",
    "            if np.zeros(data_config[dataset].params).tolist() == s_grad[0].tolist():\n",
    "                g_diff = n_grad[0]\n",
    "            elif np.zeros(data_config[dataset].params).tolist() == n_grad[0].tolist():\n",
    "                g_diff = s_grad[0]\n",
    "            else:\n",
    "                g_diff = np.array(s_grad[0] == n_grad[0], dtype = float)                \n",
    "            for sens in sens_params:\n",
    "                g_diff[sens - 1] = 0                \n",
    "            cal_grad = s_grad * g_diff\n",
    "            \n",
    "            if np.zeros(input_shape[1]).tolist() == cal_grad.tolist()[0]:\n",
    "                index = np.random.randint(len(cal_grad[0]) - 1)\n",
    "                for i in range(len(sens_params) - 1, -1, -1):\n",
    "                    if index == sens_params[i] - 1 :\n",
    "                        index = index + 1\n",
    "                            \n",
    "                cal_grad[0][index]  = np.random.choice([1.0, -1.0])\n",
    "            sample[0] = clip(sample[0] + perturbation_size * cal_grad[0], data_config[dataset]).astype(\"int\")\\\n",
    "            \n",
    "        seed_num += 1\n",
    "        \n",
    "        print('Max K  => ', max_k)\n",
    "        print('Max K time  => ', round(max_k_time,4))    \n",
    "#         print('Generated global samples',len(global_disc_inputs_list))\n",
    "#         print('Generated local samples',len(local_disc_inputs_list),'\\n')\n",
    "    print('Time to find the 1st discrimination',time_first_disc)    \n",
    "    print('Total Time =', time.time()-time1)\n",
    "    \n",
    "    # create the folder for storing the fairness testing result\n",
    "    if not os.path.exists('../results/'):\n",
    "        os.makedirs('../results/')\n",
    "    if not os.path.exists('../results/' + dataset + '/'):\n",
    "        os.makedirs('../results/' + dataset + '/')\n",
    "    if not os.path.exists('../results/' + dataset + '/RQ1&2/'):\n",
    "        os.makedirs('../results/' + dataset + '/RQ1&2/')\n",
    "\n",
    "    # storing the fairness testing result\n",
    "    np.save('../results/' + dataset + '/RQ1&2/global_samples_1.npy', np.array(global_disc_inputs_list))\n",
    "    np.save('../results/' + dataset + '/RQ1&2/local_samples_1.npy', np.array(local_disc_inputs_list))\n",
    "\n",
    "    f = open('../results/' + dataset + '/RQ1&2/final_disc_instances.csv', 'w')\n",
    "    writer = csv.writer(f)\n",
    "    for sample in local_disc_inputs_list: \n",
    "        disc=0\n",
    "        samples = m_instance( np.array([sample])[:,:-4] , sens_params, data_config[dataset])\n",
    "        labels = model_argmax(sess, x, preds, np.array(samples).reshape(len(samples),input_shape[1]))\n",
    "              \n",
    "        if (1 in labels) and (0 in labels):           \n",
    "            disc += len(np.where(labels == 0)[0])\n",
    "            total_dis += len(np.where(labels == 0)[0])\n",
    "            writer.writerow(sample + [disc])\n",
    "            \n",
    "    print('Total dics',total_dis) \n",
    "    \n",
    "    global_test = 0\n",
    "    for sample in global_disc_inputs_list: \n",
    "        disc = 0\n",
    "        samples = m_instance( np.array([sample])[:,:-4] , sens_params, data_config[dataset])\n",
    "        labels = model_argmax(sess, x, preds, np.array(samples).reshape(len(samples),input_shape[1]))\n",
    "\n",
    "        if (1 in labels) and (0 in labels):\n",
    "            global_test += 1\n",
    "            disc += len(np.where(labels == 0)[0])\n",
    "            total_dis += len(np.where(labels == 0)[0])\n",
    "            writer.writerow(sample + [disc])\n",
    "    \n",
    "    print('global disc ',global_test)\n",
    "    print('Total loc samples = ',len(local_disc_inputs_list)) \n",
    "    print('Total glob samples = ',len(global_disc_inputs_list)) \n",
    "    print('Total Dis = ',total_dis)\n",
    "    print('Local search success rate = ',(total_dis / (len(local_disc_inputs_list)*len(samples))) * 100, '%')\n",
    "       \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def main(argv=None):\n",
    "    dnn_fair_testing(dataset = FLAGS.dataset, \n",
    "                     sens_params = FLAGS.sens_params,\n",
    "                     model_path  = FLAGS.model_path,\n",
    "                     cluster_num = FLAGS.cluster_num,\n",
    "                     max_global  = FLAGS.max_global,\n",
    "                     max_local   = FLAGS.max_local,\n",
    "                     max_iter    = FLAGS.max_iter,\n",
    "                     epsillon    = FLAGS.epsillon,\n",
    "                     max_k_iter  = FLAGS.max_k_iter)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    flags.DEFINE_string(\"dataset\", \"census\", \"the name of dataset\")\n",
    "    flags.DEFINE_string('model_path', '../models/', 'the path for testing model')\n",
    "    flags.DEFINE_integer('cluster_num', 4, 'the number of clusters to form as well as the number of centroids to generate')\n",
    "    flags.DEFINE_integer('max_global', 1000, 'maximum number of samples for global search')#1000\n",
    "    flags.DEFINE_integer('max_local', 50, 'maximum number of samples for local search')#1000\n",
    "    flags.DEFINE_integer('max_iter', 100, 'maximum iteration of global perturbation')\n",
    "    flags.DEFINE_list('sens_params', [9,8,1], 'sensitive parameters index.1 for age, 9 for gender, 8 for race')\n",
    "    flags.DEFINE_float('epsillon', 0.025, 'the value of epsillon for partitioning')\n",
    "    flags.DEFINE_float('max_k_iter', 0.3, 'the percentage of max_iter if K is not increased')\n",
    "    tf.app.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes 0 0\n",
      "yes 0 1\n"
     ]
    }
   ],
   "source": [
    "for sex in range(2):\n",
    "    for race in range(5):\n",
    "        if df[(df[8]==sex)&(df[7]==race)]['labels'].sum()>0:\n",
    "            print('yes',race,sex)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0  7  8  labels\n",
       "0   1  0  0       0\n",
       "1   2  0  0       0\n",
       "2   3  0  0       0\n",
       "3   4  0  0       0\n",
       "4   5  0  0       0\n",
       "5   6  0  0       0\n",
       "6   7  0  0       1\n",
       "7   8  0  0       0\n",
       "8   9  0  0       0\n",
       "45  1  0  1       0\n",
       "46  2  0  1       0\n",
       "47  3  0  1       0\n",
       "48  4  0  1       0\n",
       "49  5  0  1       1\n",
       "50  6  0  1       1\n",
       "51  7  0  1       1\n",
       "52  8  0  1       1\n",
       "53  9  0  1       0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df[7]==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0  7  8  labels\n",
       "0   1  0  0       0\n",
       "1   2  0  0       0\n",
       "2   3  0  0       0\n",
       "3   4  0  0       0\n",
       "4   5  0  0       0\n",
       ".. .. .. ..     ...\n",
       "85  5  4  1       0\n",
       "86  6  4  1       1\n",
       "87  7  4  1       1\n",
       "88  8  4  1       1\n",
       "89  9  4  1       1\n",
       "\n",
       "[90 rows x 4 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
