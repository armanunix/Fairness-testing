{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../models/bank/test.model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0110 13:24:38.026928 140403317155648 saver.py:1399] Restoring parameters from ../models/bank/test.model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 100\n",
      "Batch 200\n",
      "Batch 300\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9296d9cbdef8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_path'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../models/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'the path for testing model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sens_params'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'sensitive parameters index.1 for age, 9 for gender, 8 for race'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/tensorflow/python/platform/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mmain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'__main__'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags_parser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_parse_flags_tolerate_undef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3/dist-packages/absl/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv, flags_parser)\u001b[0m\n\u001b[1;32m    310\u001b[0m       \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m       \u001b[0m_run_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mUsageError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m       \u001b[0musage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshorthelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdetailed_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexitcode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexitcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/absl/app.py\u001b[0m in \u001b[0;36m_run_main\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-9296d9cbdef8>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m     dnn_fair_testing(dataset = FLAGS.dataset, \n\u001b[0m\u001b[1;32m    377\u001b[0m                      \u001b[0msens_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msens_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m                      model_path  = FLAGS.model_path)\n",
      "\u001b[0;32m<ipython-input-3-9296d9cbdef8>\u001b[0m in \u001b[0;36mdnn_fair_testing\u001b[0;34m(dataset, sens_params, model_path)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0meval_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mini_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m         \u001b[0mnum_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0mnum_rand_point_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;31m# number of random points in range(0 to mean)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m             )\n\u001b[0;32m--> 860\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    861\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    894\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "\n",
    "import  os\n",
    "#import psutil\n",
    "# p = psutil.Process(os.getpid())\n",
    "# p.cpu_affinity(0)\n",
    "import numpy as np\n",
    "from itertools import product, combinations\n",
    "import tensorflow.compat.v1 as tf \n",
    "tf.compat.v1.disable_eager_execution()\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import copy\n",
    "import time\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from tensorflow.python.platform import flags\n",
    "from adf_data.bank import bank_data\n",
    "from adf_model.tutorial_models import dnn\n",
    "from adf_utils.utils_tf import model_prediction, model_argmax , layer_out, model_eval\n",
    "from adf_utils.config import bank\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "FLAGS = flags.FLAGS\n",
    "       \n",
    "def m_instance( sample, sens_params, conf):\n",
    "    index = []\n",
    "    m_sample = []\n",
    "    for sens in sens_params:\n",
    "        index.append([i for i in range(conf.input_bounds[sens - 1][0], conf.input_bounds[sens-1][1] + 1)])\n",
    "      \n",
    "    for ind in list(product(*index)):     \n",
    "        temp = sample.copy()\n",
    "        for i in range(len(sens_params)):\n",
    "            temp[0][sens_params[i]-1] = ind[i]\n",
    "        m_sample.append(temp)\n",
    "    return np.array(m_sample)\n",
    "    \n",
    "def clustering(probs,m_sample, sens_params, epsilon=0.025):\n",
    "    cluster_dic = {}\n",
    "    cluster_dic['Seed'] = m_sample[0][0]\n",
    "    bins= np.arange(0, 1, epsilon )\n",
    "    digitized = np.digitize(probs, bins) - 1\n",
    "    for  k in range(len(digitized)):\n",
    "\n",
    "        if digitized[k] not in cluster_dic.keys():        \n",
    "            cluster_dic[digitized[k]]=[ [m_sample[k][0][j - 1] for j in sens_params]]\n",
    "        else:\n",
    "            cluster_dic[digitized[k]].append( [m_sample[k][0][j - 1] for j in sens_params])\n",
    "    return cluster_dic \n",
    "\n",
    "    \n",
    "def pred_prob(sess, x, preds, m_sample, input_shape):\n",
    "        probs = model_prediction(sess, x, preds, np.array(m_sample).reshape(len(m_sample),\n",
    "                                    input_shape[1]))[:,1:2].reshape(len(m_sample))\n",
    "        return probs        \n",
    "        \n",
    "def neuron_locator(sess, model, samples, layer_number,model_path, input_shape, \n",
    "                   nb_classes, dataset, sens_params, update_list  ):\n",
    "        \n",
    "        if  sess._closed:\n",
    "#             config = tf.ConfigProto()\n",
    "#             config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "            config = tf.ConfigProto(device_count = {'GPU': 0})\n",
    "            config.allow_soft_placement= True            \n",
    "            sess   = tf.Session(config = config)\n",
    "            x      = tf.placeholder(tf.float32, shape = input_shape)\n",
    "            y      = tf.placeholder(tf.float32, shape = (None, nb_classes))\n",
    "            model  = dnn(input_shape, nb_classes)   \n",
    "            preds  = model(x)\n",
    "            saver  = tf.train.Saver()\n",
    "            saver.restore(sess, model_path)\n",
    "            \n",
    "        num_layers = len(model.layers)\n",
    "        feed_dic = {}\n",
    "        for neuron in range(len(update_list)):           \n",
    "            for layer in range(0,num_layers - 1,2):\n",
    "                if layer == 0:\n",
    "                    l = model.layers[layer].fprop(samples.astype('float32'))\n",
    "                else:\n",
    "                    l = model.layers[layer].fprop(r)                   \n",
    "                if layer + 1 == (layer_number * 2) - 1:\n",
    "                    indices = []\n",
    "                    for instance in range(l.shape[0]):                       \n",
    "                        indices.append([ instance, 0, neuron])       \n",
    "                    updates = [ update_list[ neuron ] ] * l.shape[0]\n",
    "                    r = model.layers[layer + 1].fprop(l , indices, updates)\n",
    "                else:\n",
    "                    r = model.layers[layer + 1].fprop(l)\n",
    "            feed_dic[neuron] = r\n",
    "        all_probs = sess.run(feed_dic)\n",
    "        out_dic   = {}\n",
    "        for key in all_probs.keys():\n",
    "            probs = np.array(all_probs[key]).reshape((9,2))[:,1:].reshape((9))\n",
    "            clus  = clustering(probs,samples, sens_params)\n",
    "            out_dic[key] = [len(clus) - 1 ]\n",
    "        sess.close()\n",
    "        tf.reset_default_graph()\n",
    "        return out_dic\n",
    "    \n",
    "def model_acc(sess, model,model_path,input_shape, nb_classes,\n",
    "              dataset, sens_params,neuron,X,Y,layer_number,num_layers,update_list):\n",
    "        \n",
    "        if  sess._closed:\n",
    "#                 config = tf.ConfigProto()\n",
    "#                 config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "                config = tf.ConfigProto(device_count = {'GPU': 0})\n",
    "                config.allow_soft_placement= True\n",
    "                sess   = tf.Session(config = config)\n",
    "                x      = tf.placeholder(tf.float32, shape = input_shape)\n",
    "                y      = tf.placeholder(tf.float32, shape = (None, nb_classes))\n",
    "                model  = dnn(input_shape, nb_classes)   \n",
    "                preds  = model(x)\n",
    "                saver  = tf.train.Saver()\n",
    "                saver.restore(sess, model_path)\n",
    "        feed_dic = {}        \n",
    "        for layer in range(0,num_layers - 1,2):\n",
    "            if layer == 0:\n",
    "                l = model.layers[layer].fprop(X.astype('float32'))\n",
    "            else:\n",
    "                l = model.layers[layer].fprop(r)          \n",
    "            if layer + 1 == (layer_number * 2) - 1:\n",
    "                indices = []\n",
    "                for instance in range(l.shape[0]):                       \n",
    "                    indices.append([ instance, neuron])                \n",
    "                updates = [ update_list[ neuron ] ] * l.shape[0]                \n",
    "                r = model.layers[layer + 1].fprop(l , indices, updates)\n",
    "            else:\n",
    "                r = model.layers[layer + 1].fprop(l)             \n",
    "        all_probs = sess.run(r)\n",
    "        out_class = []\n",
    "        for out in all_probs:\n",
    "            out_class.append(np.argmax(out))\n",
    "        truth_val = []\n",
    "        for tr in Y:\n",
    "                truth_val.append(np.argmax(tr))\n",
    "        acc = 0\n",
    "        for i in range(len(out_class)):\n",
    "            if out_class[i] == truth_val[i]:\n",
    "                acc += 1\n",
    "        accuracy = round(acc/len(out_class),3)\n",
    "        sess.close()\n",
    "        tf.reset_default_graph()\n",
    "        return accuracy \n",
    "\n",
    "def get_rate(sess, model, model_path, input_shape, nb_classes,\n",
    "              dataset, lay_name, layer_output):\n",
    "        \n",
    "        def get_distance(vec1, vec2, size):\n",
    "            return abs(vec1 - vec2).sum() / size\n",
    "        \n",
    "        max_dis = 0\n",
    "        epsillon = 10 ** -7\n",
    "        num_samples = len(layer_output[lay_name])\n",
    "        #print('lay_name',lay_name)\n",
    "        layer_ind = np.where(np.array(list(layer_output.keys())) == lay_name)[0][0]\n",
    "\n",
    "        for ind in range(layer_ind):\n",
    "            temp_dis = 0\n",
    "            if 'ReLU' in np.array(list(layer_output.keys()))[ind]:\n",
    "                layer_name = np.array(list(layer_output.keys()))[ind]\n",
    "                layer_size  = len(layer_output[layer_name][0][0])\n",
    "                distances = np.zeros((num_samples,num_samples))\n",
    "                \n",
    "                for i in combinations(range(num_samples),2):\n",
    "                    distances[i[0],i[1]] = get_distance(layer_output[layer_name][i[0]],\n",
    "                                                        layer_output[layer_name][i[1]],layer_size)\n",
    "                if distances.max()> max_dis:\n",
    "                    max_dis = distances.max()                                      \n",
    "        distances = np.zeros((num_samples,num_samples))       \n",
    "        for i in combinations(range(num_samples),2):\n",
    "            distances[i[0],i[1]] = get_distance(layer_output[lay_name][i[0]],layer_output[lay_name][i[1]],len(layer_output[lay_name][0][0]))\n",
    "        cur_dis = distances.max()\n",
    "        change_rate = (cur_dis - max_dis ) / (max_dis + epsillon)\n",
    "        return change_rate\n",
    "    \n",
    "def layer_locator(sess, model, model_path,sens_params, input_shape, nb_classes,\n",
    "              dataset,conf, samples):\n",
    "        if  sess._closed:\n",
    "    #                 config = tf.ConfigProto()\n",
    "    #                 config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "            config = tf.ConfigProto(device_count = {'GPU': 0})\n",
    "            config.allow_soft_placement= True\n",
    "            sess   = tf.Session(config = config)\n",
    "            x      = tf.placeholder(tf.float32, shape = input_shape)\n",
    "            y      = tf.placeholder(tf.float32, shape = (None, nb_classes))\n",
    "            model  = dnn(input_shape, nb_classes)   \n",
    "            preds  = model(x)\n",
    "            saver  = tf.train.Saver()\n",
    "            saver.restore(sess, model_path)\n",
    "            \n",
    "        layer_list = []\n",
    "        for sample in samples:            \n",
    "            samples = m_instance( np.array([sample]) , sens_params, conf)\n",
    "            layer_output = layer_out(sess,model,np.array(samples).astype('float32')) \n",
    "            temp_list = []\n",
    "            for layer in layer_output.keys():\n",
    "                if 'ReLU' in layer:\n",
    "                    temp_rate = get_rate(sess, model, model_path, input_shape, nb_classes,\n",
    "                                          dataset,layer, layer_output)\n",
    "                    temp_list.append(temp_rate)             \n",
    "            layer_list.append((np.argmax(np.array(temp_list[1:])) + 2 ))\n",
    "        sess.close()\n",
    "        tf.reset_default_graph()    \n",
    "        return stats.mode(layer_list)[0][0]      \n",
    "#-------------------------------------------\n",
    "    \n",
    "def dnn_fair_testing(dataset, sens_params, model_path):\n",
    "\n",
    "    data = {\"bank\":bank_data}\n",
    "           \n",
    "    data_config = {\"bank\":bank}\n",
    "    global ini_acc\n",
    "    # prepare the testing data and model\n",
    "    X, Y, input_shape, nb_classes = data[dataset]()\n",
    "    tf.set_random_seed(1234)\n",
    "    layer_numbers=[]\n",
    "    for trial in range(1):\n",
    "        config = tf.ConfigProto(device_count = {'GPU': 0})\n",
    "        config.allow_soft_placement= True\n",
    "       # with tf.device('/CPU:1'):\n",
    "        sess  = tf.Session(config = config)\n",
    "        x     = tf.placeholder(tf.float32, shape = input_shape)\n",
    "        y     = tf.placeholder(tf.float32, shape = (None, nb_classes))\n",
    "        model = dnn(input_shape, nb_classes)   \n",
    "\n",
    "        preds = model(x)\n",
    "        saver = tf.train.Saver()\n",
    "        model_path ='../models/'\n",
    "        model_path = model_path + dataset + \"/test.model\"\n",
    "        saver.restore(sess, model_path)\n",
    "        eval_params = {'batch_size': 128}\n",
    "        ini_acc = round(model_eval(sess, x, y, preds, X, Y, args=eval_params),3)\n",
    "        num_trial = 11\n",
    "        num_rand_point_1 = 4 # number of random points in range(0 to mean)\n",
    "        num_rand_point_2 = 3 # number of random points in range(mean to std)\n",
    "        num_rand_point_3 = 1 # number of random points in range(mean + std to  mean + 2 * std)\n",
    "        time1 = time.time()\n",
    "    # Loading the result of QID\n",
    "        layer_output = layer_out(sess,model,X.astype('float32'))\n",
    "        input_df  = pd.read_csv('../results/' + dataset + '/OurTool/RQ3/total_disc_'+str(trial)+'.csv',header='infer')\n",
    "        input_df = input_df.drop(columns=['Unnamed: 0'])       \n",
    "        sample_df = input_df.copy()\n",
    "        sample_df_rand = sample_df.sample(n = 90,axis = 0,random_state = np.random.RandomState())\n",
    "        sample_df_maxk = sample_df.sort_values(by = 'k',ascending=False).head(10)\n",
    "        sample_df = pd.concat([sample_df_rand,sample_df_maxk])\n",
    "        ini_k_samples = sample_df['k']\n",
    "        sample_df = sample_df.drop(columns = ['sh_entropy', 'k', 'disc', 'min_entropy']) \n",
    "        samples   = sample_df.to_numpy()\n",
    "        num_samples = len(samples)\n",
    "        print(num_samples)\n",
    "#         layer_number = layer_locator(sess, model, model_path, sens_params, input_shape, nb_classes,\n",
    "#               dataset,data_config[dataset], samples)\n",
    "        layer_number = 2\n",
    "        layer_numbers.append(layer_number)\n",
    "        print(layer_number,time.time() - time1)\n",
    "        #-----------------------------\n",
    "        update_df = layer_output['ReLU'+str((2*layer_number) -1 )]\n",
    "        update_min  = np.min(update_df,axis=0)\n",
    "        update_max  = np.max(update_df,axis=0)\n",
    "        update_mean = np.mean(update_df,axis=0)\n",
    "        update_std  = np.std(update_df,axis=0)\n",
    "        update_list = []\n",
    "        update_list.append(update_min)\n",
    "        rand_point_1 = np.sort(np.random.random(num_rand_point_1))\n",
    "        for i in range(len(rand_point_1)):\n",
    "            update_list.append(rand_point_1[i] * update_mean)\n",
    "        update_list.append(update_mean)\n",
    "        rand_point_2 = np.sort(np.random.random(num_rand_point_2))\n",
    "        for i in range(len(rand_point_2)):\n",
    "            update_list.append(update_mean + rand_point_2[i] * update_std)\n",
    "        update_list.append(update_mean + update_std +  np.random.random(num_rand_point_3)[0] * update_std)        \n",
    "        update_list.append(update_max)\n",
    "        layer_size   = model.layers[(layer_number*2) - 1].input_shape[1]\n",
    "        layer_name   = model.layers[(layer_number*2) - 1]\n",
    "        num_layers   = len(model.layers)\n",
    "\n",
    "        all_dic = {}\n",
    "        accu_neuron = {}\n",
    "        acc_try = {}\n",
    "        sample_ind = 0\n",
    "        time1 = time.time()\n",
    "        for sample in samples:       \n",
    "            update_list_man = np.array([0] * layer_size)\n",
    "            m_samples  = m_instance( np.array([sample]), sens_params, data_config[dataset])\n",
    "            change_dic = {}\n",
    "            for i in range(num_trial):\n",
    "                update_list_man = update_list[i]               \n",
    "                x = neuron_locator(sess, model, m_samples, layer_number,model_path,\n",
    "                               input_shape, nb_classes, dataset, sens_params, update_list_man )\n",
    "                if sample_ind == 0:\n",
    "                    accu_neuron = {}\n",
    "                    for neuron in range(len(update_list_man)):\n",
    "                        accu_neuron[neuron] = model_acc(sess, model,model_path,\n",
    "                                         input_shape, nb_classes, dataset, sens_params,\n",
    "                                         neuron,X,Y,layer_number,num_layers,update_list_man)\n",
    "                    acc_try[i] = accu_neuron                 \n",
    "                change_dic[i] = x  \n",
    "            all_dic[sample_ind] = change_dic\n",
    "            clear_output(wait=True)\n",
    "            sample_ind += 1\n",
    "\n",
    "        # create the folder for storing the fairness testing result\n",
    "        if not os.path.exists('../results/'):\n",
    "            os.makedirs('../results/')\n",
    "        if not os.path.exists('../results/' + dataset + '/'):\n",
    "            os.makedirs('../results/' + dataset + '/')\n",
    "        if not os.path.exists('../results/' + dataset + '/OurTool/'):\n",
    "            os.makedirs('../results/' + dataset + '/OurTool/')\n",
    "        if not os.path.exists('../results/' + dataset + '/OurTool/RQ3/'):\n",
    "            os.makedirs('../results/' + dataset + '/OurTool/RQ3/')          \n",
    "        if not os.path.exists('../results/' + dataset + '/OurTool/RQ3/table2/'):\n",
    "            os.makedirs('../results/' + dataset + '/OurTool/RQ3/table2/')\n",
    "        np.save('../results/'+dataset+'/OurTool/RQ3/table2/inik_'+str(num_samples)+'_'+str(trial)+'.npy',\n",
    "                np.array(ini_k_samples))\n",
    "        np.save('../results/'+dataset+'/OurTool/RQ3/table2/accu_dic_'+str(num_samples)+'_'+str(trial)+'.npy',\n",
    "                acc_try) \n",
    "        np.save('../results/'+dataset+'/OurTool/RQ3/table2/all_dic_'+str(num_samples)+'_'+str(trial)+'.npy', \n",
    "                all_dic)   \n",
    "\n",
    "        accu_dic = dict(np.load('../results/'+dataset+'/OurTool/RQ3/table2/accu_dic_'+str(num_samples)+'_'+str(trial)+'.npy',\n",
    "                                allow_pickle=True).item())  \n",
    "        all_dic  = dict(np.load('../results/'+dataset+'/OurTool/RQ3/table2/all_dic_'+str(num_samples)+'_'+str(trial)+'.npy',\n",
    "                               allow_pickle=True).item())\n",
    "        ini_k = np.load('../results/'+dataset+'/OurTool/RQ3/table2/inik_'+str(num_samples)+'_'+str(trial)+'.npy')\n",
    "\n",
    "        num_samples = len(all_dic.keys())\n",
    "        num_force   = len(all_dic[0].keys())\n",
    "        num_neuron  = len(all_dic[0][0].keys())\n",
    "        ini_k = np.repeat(ini_k, (num_force * num_neuron))\n",
    "        data  = np.zeros(((num_samples * num_force * num_neuron) ,4) , dtype = 'int32')\n",
    "        df    = pd.DataFrame(data,columns = ['sample','force','neuron','K'],dtype = 'int32')\n",
    "        sample_col = np.repeat(np.array([i for i in range(num_samples)]),(num_neuron * num_force))\n",
    "        force_col  = np.array([ int(i/num_neuron ) for i in range( num_neuron * num_force ) ] * num_samples)\n",
    "        neuron_col = np.array([i for i in range( num_neuron )] * ( num_samples*num_force ))\n",
    "        df['sample'] = sample_col\n",
    "        df['force']  = force_col\n",
    "        df['neuron'] = neuron_col\n",
    "        df['acc'] = 0\n",
    "        acc = pd.DataFrame(accu_dic).transpose().to_numpy()\n",
    "        acc = acc.reshape(acc.shape[0] * acc.shape[1],)\n",
    "        for i in range(len(all_dic.keys())):\n",
    "            temp = pd.DataFrame(all_dic[i]).transpose().to_numpy()\n",
    "            temp = temp.reshape(((len(all_dic[0][0].keys())) * len(all_dic[0].keys()),))   \n",
    "            df.loc[df.loc[(df['sample'] == i) ].index,'acc'] = acc\n",
    "            df.loc[df.loc[(df['sample'] == i) ].index,'K'] = temp\n",
    "        df['K'] = df['K'].transform(lambda x:x[0])\n",
    "        df['init_k'] = ini_k\n",
    "\n",
    "        R_act   = []\n",
    "        R_deact = []\n",
    "        diff_R  = []\n",
    "        acc_e   = 0.05\n",
    "        for neuron in range(num_neuron):\n",
    "            k_deact = df.loc[(df['neuron'] == neuron) & (df['force'] <= 1) & \\\n",
    "                                  (df['acc'] >= ini_acc - acc_e)]['K'].mean()\n",
    "            k_act   = df.loc[(df['neuron'] == neuron) & (df['force'] > 1) & \\\n",
    "                                  (df['acc'] >= ini_acc - acc_e)]['K'].mean()\n",
    "            k_init  = df.loc[(df['neuron'] == neuron) & (df['acc'] >= ini_acc - acc_e)]['init_k'].mean()\n",
    "            R_act_temp   = (k_act - k_init) / k_init\n",
    "            R_deact_temp = (k_deact - k_init) / k_init\n",
    "            diff_R_temp  = R_act_temp - R_deact_temp\n",
    "            R_act.append(R_act_temp)\n",
    "            R_deact.append(R_deact_temp)\n",
    "            diff_R.append(diff_R_temp)\n",
    "\n",
    "        \n",
    "        df.to_csv('../results/'+dataset+'/OurTool/RQ3/table2/df_'+str(num_samples)+'_'+str(trial)+'.csv',index=False)\n",
    "        np.save('../results/'+dataset+'/OurTool/RQ3/table2/R_act_'+str(num_samples)+'_'+str(trial)+'.npy',R_act)\n",
    "        np.save('../results/'+dataset+'/OurTool/RQ3/table2/R_deact_'+str(num_samples)+'_'+str(trial)+'.npy',R_deact)\n",
    "        np.save('../results/'+dataset+'/OurTool/RQ3/table2/R_diffR_'+str(num_samples)+'_'+str(trial)+'.npy',diff_R)\n",
    "    np.save('../results/'+dataset+'/OurTool/RQ3/table2/res_layers_'+str(num_samples)+'_'+str(trial)+'.npy',layer_numbers)\n",
    "    print('Time to intervene',time.time() - time1)\n",
    "def main(argv = None):\n",
    "    \n",
    "    dnn_fair_testing(dataset = FLAGS.dataset, \n",
    "                     sens_params = FLAGS.sens_params,\n",
    "                     model_path  = FLAGS.model_path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    flags.DEFINE_string(\"dataset\", \"bank\", \"the name of dataset\")\n",
    "    flags.DEFINE_string('model_path', '../models/', 'the path for testing model')\n",
    "    flags.DEFINE_list('sens_params',[1],'sensitive parameters index.1 for age, 9 for gender, 8 for race')\n",
    "    tf.app.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('../results/bank/OurTool/RQ3/table2_11/df_100_0.csv')\n",
    "df2=pd.read_csv('../results/bank/OurTool/RQ3/table2_2/df_100_0.csv')\n",
    "acc_e   = 0.03\n",
    "ini_acc = 0.923"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df2\n",
    "R_act   = []\n",
    "R_deact = []\n",
    "diff_R  = []\n",
    "acc_e   = 0.05\n",
    "for neuron in range(num_neuron):\n",
    "    k_deact = df.loc[(df['neuron'] == neuron) & (df['force'] == 0) & \\\n",
    "                          (df['acc'] >= ini_acc - acc_e)]['K'].mean()\n",
    "    k_act   = df.loc[(df['neuron'] == neuron) & (df['force'] == 1) & \\\n",
    "                          (df['acc'] >= ini_acc - acc_e)]['K'].mean()\n",
    "    k_init  = df.loc[(df['neuron'] == neuron) & (df['acc'] >= ini_acc - acc_e)]['init_k'].mean()\n",
    "    R_act_temp   = (k_act - k_init) / k_init\n",
    "    R_deact_temp = (k_deact - k_init) / k_init\n",
    "    diff_R_temp  = R_act_temp - R_deact_temp\n",
    "    R_act.append(R_act_temp)\n",
    "    R_deact.append(R_deact_temp)\n",
    "    diff_R.append(round(diff_R_temp,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nan,\n",
       " 0.0,\n",
       " -0.8249,\n",
       " nan,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.8599,\n",
       " nan,\n",
       " 0.0,\n",
       " -0.8249,\n",
       " -0.0018,\n",
       " nan,\n",
       " -0.8249,\n",
       " -0.8459,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.8179,\n",
       " nan,\n",
       " -0.8091,\n",
       " -0.8266,\n",
       " nan,\n",
       " 0.0,\n",
       " -0.8161,\n",
       " 0.0,\n",
       " -0.8214,\n",
       " nan,\n",
       " 0.0053,\n",
       " 0.0,\n",
       " nan,\n",
       " 0.0,\n",
       " nan,\n",
       " nan]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0128,\n",
       " 0.0,\n",
       " -0.5129,\n",
       " 0.0116,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.4456,\n",
       " 0.0086,\n",
       " 0.0,\n",
       " -0.4704,\n",
       " -0.0002,\n",
       " -0.0168,\n",
       " -0.4105,\n",
       " -0.4294,\n",
       " 0.0,\n",
       " 0.0,\n",
       " -0.1553,\n",
       " -0.2888,\n",
       " -0.1636,\n",
       " -0.1767,\n",
       " 0.3131,\n",
       " 0.0,\n",
       " -0.2777,\n",
       " 0.0,\n",
       " -0.2088,\n",
       " 0.0076,\n",
       " 0.0007,\n",
       " 0.0,\n",
       " -0.0258,\n",
       " 0.0,\n",
       " -0.0152,\n",
       " -0.0435]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dic  = dict(np.load('../results/bank/OurTool/RQ3/table2_2/all_dic_100_0.npy', allow_pickle=True).item())\n",
    "ini_k = np.load('../results/bank/OurTool/RQ3/table2_2/inik_100_0.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(all_dic.keys())\n",
    "num_force   = len(all_dic[0].keys())\n",
    "num_neuron  = len(all_dic[0][0].keys())\n",
    "ini_k = np.repeat(ini_k, (num_force * num_neuron))\n",
    "data  = np.zeros(((num_samples * num_force * num_neuron) ,4) , dtype = 'int32')\n",
    "df    = pd.DataFrame(data,columns = ['sample','force','neuron','K'],dtype = 'int32')\n",
    "sample_col = np.repeat(np.array([i for i in range(num_samples)]),(num_neuron * num_force))\n",
    "force_col  = np.array([ int(i/num_neuron ) for i in range( num_neuron * num_force ) ] * num_samples)\n",
    "neuron_col = np.array([i for i in range( num_neuron )] * ( num_samples*num_force ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample</th>\n",
       "      <th>force</th>\n",
       "      <th>neuron</th>\n",
       "      <th>K</th>\n",
       "      <th>acc</th>\n",
       "      <th>init_k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.915</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.923</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.921</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.911</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.923</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6395</th>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>0.923</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6396</th>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0.413</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6397</th>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>0.923</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6398</th>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>0.270</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6399</th>\n",
       "      <td>99</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>0.405</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6400 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      sample  force  neuron  K    acc  init_k\n",
       "0          0      0       0  5  0.915       5\n",
       "1          0      0       1  5  0.923       5\n",
       "2          0      0       2  5  0.921       5\n",
       "3          0      0       3  5  0.911       5\n",
       "4          0      0       4  5  0.923       5\n",
       "...      ...    ...     ... ..    ...     ...\n",
       "6395      99      1      27  9  0.923       9\n",
       "6396      99      1      28  1  0.413       9\n",
       "6397      99      1      29  9  0.923       9\n",
       "6398      99      1      30  1  0.270       9\n",
       "6399      99      1      31  1  0.405       9\n",
       "\n",
       "[6400 rows x 6 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
